# -*- coding: utf-8 -*-
"""Sentiment _Predictor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zy6UBLS9ffjBxION0rpX0pcNEFgNxyxJ

# **SENTIMENT ANALYSIS and PREDICTOR using NLP**
"""

#Import the necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense
from tensorflow.keras.layers import Dropout, Bidirectional,Conv1D,MaxPooling1D,AveragePooling1D,Flatten
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, confusion_matrix

df=pd.read_csv('/content/drive/MyDrive/CDC/Sentiment_Dataset/train.csv', encoding='latin1')
df.head()

df.columns

df1=df.drop(['textID','Time of Tweet','Age of User','Country', 'Population -2020', 'Land Area (Km²)','Density (P/Km²)'],axis=1)
df1.head()

df1.dropna()

df1.sentiment.value_counts()

"""The data is ready to be feeded.

**MODEL TRAINING**
"""

import re
def clean_text(text):
    # Check if the input is a string
    if isinstance(text, str):
        # Remove all numeric values (including floats)
        text = re.sub(r'\d+(\.\d+)?', '', text)
        # Remove all non-alphabetic characters
        cleaned_text = re.sub('[^A-Za-z\s]+', '', text)
        return cleaned_text.strip()  # Remove leading/trailing whitespace
    else:
        return text

df1['text'] = df1['text'].apply(clean_text)


df1.head()

map={'negative':0,'neutral':1,'positive':2}
df1['sentiment']=df1['sentiment'].map(map)
df1.head()

text = df1['text'].astype(str).tolist()
label=df1['sentiment']

training_size=int(len(text)*0.8)

training_text=text[:training_size]
testing_text=text[training_size:]
training_label=label[:training_size]
testing_label=label[training_size:]

training_text

tokenizer=Tokenizer(num_words=10000,oov_token="OOV")
tokenizer.fit_on_texts(training_text)

word_index=tokenizer.word_index
training_text=tokenizer.texts_to_sequences(training_text)
testing_text=tokenizer.texts_to_sequences(testing_text)
training_padded=pad_sequences(training_text,maxlen=100,padding='post',truncating='post')
testing_padded=pad_sequences(testing_text,maxlen=100,padding='post')

training_padded=np.array(training_padded)
testing_padded=np.array(testing_padded)
training_label=np.array(training_label)
testing_label=np.array(testing_label)

model=Sequential()
model.add(Embedding(10000,16,input_length=100))
model.add(Bidirectional(LSTM(64)))
model.add(Dropout(0.5))
model.add(Dense(3,activation='softmax'))
model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
model.summary()

epochs=30
from tensorflow.keras.callbacks import EarlyStopping

early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

history=model.fit(training_padded,training_label,epochs=epochs,validation_data=(testing_padded,testing_label),callbacks=[early_stopping])

# Convert the model to TFLite format with Select TF ops
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.target_spec.supported_ops = [
    tf.lite.OpsSet.TFLITE_BUILTINS,  # Enable TensorFlow Lite ops.
    tf.lite.OpsSet.SELECT_TF_OPS     # Enable Select TF ops.
]
converter._experimental_lower_tensor_list_ops = False

try:
    tflite_model = converter.convert()
    # Save the TFLite model to a file
    tflite_model_file = 'model.tflite'
    with open(tflite_model_file, 'wb') as f:
        f.write(tflite_model)
    print(f"TFLite model saved to {tflite_model_file}")
except Exception as e:
    print("Error converting model to TFLite:", e)

def plot_graphs(history, string):
  plt.plot(history.history[string])
  plt.plot(history.history['val_'+string])
  plt.xlabel("Epochs")
  plt.ylabel(string)
  plt.legend([string, 'val_'+string])
  plt.show()

plot_graphs(history, "accuracy")
plot_graphs(history, "loss")

reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])

def decode_sentence(text):
    return ' '.join([reverse_word_index.get(i, '?') for i in text])

print(decode_sentence(training_padded[0]))
print(training_text[2])
print(label[2])

e = model.layers[0]
weights = e.get_weights()[0]
print(weights.shape) # shape: (vocab_size, embedding_dim)

import io

out_v = io.open('vecs.tsv', 'w', encoding='utf-8')
out_m = io.open('meta.tsv', 'w', encoding='utf-8')
for word_num in range(1, 10000):
  word = reverse_word_index[word_num]
  embeddings = weights[word_num]
  out_m.write(word + "\n")
  out_v.write('\t'.join([str(x) for x in embeddings]) + "\n")
out_v.close()
out_m.close()

try:
  from google.colab import files
except ImportError:
  pass
else:
  files.download('vecs.tsv')
  files.download('meta.tsv')

def predict_sentiment(text):
  sequences = tokenizer.texts_to_sequences(text)
  padded = pad_sequences(sequences, maxlen=100, padding="post", truncating="post")
  predictions =model.predict(padded)
  predicted_classes = np.argmax(predictions, axis=1)
  for i in range(len(predicted_classes)):
    if predicted_classes[i] == 0:
      print("The sentiment of the comment is Negative")
    elif predicted_classes[i] == 1:
      print("The sentiment of the comment is Neutral")
    elif predicted_classes[i] == 2:
      print("The sentiment of the comment is Positive")

sentences = ["Ohh thats so sad!!", "game of thrones season finale showing this sunday night"]
predict_sentiment(sentences)

sentence = ["Ohh thats so sad!!", "game of thrones season finale showing this sunday night"]
sequences = tokenizer.texts_to_sequences(sentence)
padded = pad_sequences(sequences, maxlen=100, padding="post", truncating="post")
predicted_classes = np.argmax(model.predict(padded), axis=1)
print(predicted_classes)